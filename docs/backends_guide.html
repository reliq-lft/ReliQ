<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!--  This file is generated by Nim. -->
<html xmlns="https://www.w3.org/1999/xhtml" xml:lang="en" lang="en" data-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>backends_guide</title>

<!-- Google fonts -->
<link href='https://fonts.googleapis.com/css?family=Lato:400,600,900' rel='stylesheet' type='text/css'/>
<link href='https://fonts.googleapis.com/css?family=Source+Code+Pro:400,500,600' rel='stylesheet' type='text/css'/>

<!-- Favicon -->
<link rel="shortcut icon" href="data:image/x-icon;base64,AAABAAEAEBAAAAEAIABoBAAAFgAAACgAAAAQAAAAIAAAAAEAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAUAAAAF////AP///wD///8A////AP///wD///8A////AP///wD///8A////AAAAAAIAAABbAAAAlQAAAKIAAACbAAAAmwAAAKIAAACVAAAAWwAAAAL///8A////AP///wD///8A////AAAAABQAAADAAAAAYwAAAA3///8A////AP///wD///8AAAAADQAAAGMAAADAAAAAFP///wD///8A////AP///wAAAACdAAAAOv///wD///8A////AP///wD///8A////AP///wD///8AAAAAOgAAAJ3///8A////AP///wAAAAAnAAAAcP///wAAAAAoAAAASv///wD///8A////AP///wAAAABKAAAAKP///wAAAABwAAAAJ////wD///8AAAAAgQAAABwAAACIAAAAkAAAAJMAAACtAAAAFQAAABUAAACtAAAAkwAAAJAAAACIAAAAHAAAAIH///8A////AAAAAKQAAACrAAAAaP///wD///8AAAAARQAAANIAAADSAAAARf///wD///8AAAAAaAAAAKsAAACk////AAAAADMAAACcAAAAnQAAABj///8A////AP///wAAAAAYAAAAGP///wD///8A////AAAAABgAAACdAAAAnAAAADMAAAB1AAAAwwAAAP8AAADpAAAAsQAAAE4AAAAb////AP///wAAAAAbAAAATgAAALEAAADpAAAA/wAAAMMAAAB1AAAAtwAAAOkAAAD/AAAA/wAAAP8AAADvAAAA3gAAAN4AAADeAAAA3gAAAO8AAAD/AAAA/wAAAP8AAADpAAAAtwAAAGUAAAA/AAAA3wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAAD/AAAA/wAAAP8AAADfAAAAPwAAAGX///8A////AAAAAEgAAADtAAAAvwAAAL0AAADGAAAA7wAAAO8AAADGAAAAvQAAAL8AAADtAAAASP///wD///8A////AP///wD///8AAAAAO////wD///8A////AAAAAIcAAACH////AP///wD///8AAAAAO////wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A////AP///wD///8A//8AAP//AAD4HwAA7/cAAN/7AAD//wAAoYUAAJ55AACf+QAAh+EAAAAAAADAAwAA4AcAAP5/AAD//wAA//8AAA=="/>
<link rel="icon" type="image/png" sizes="32x32" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAA3XAAAN1wFCKJt4AAAAB3RJTUUH4QQQEwksSS9ZWwAAAk1JREFUWMPtll2ITVEUx39nn/O7Y5qR8f05wtCUUr6ZIS++8pEnkZInPImneaCQ5METNdOkeFBKUhMPRIkHKfEuUZSUlGlKPN2TrgfncpvmnntnmlEyq1Z7t89/rf9a6+y99oZxGZf/XeIq61EdtgKXgdXA0xrYAvBjOIF1AI9zvjcC74BSpndrJPkBWDScTF8Aa4E3wDlgHbASaANmVqlcCnwHvgDvgVfAJ+AikAAvgfVZwLnSVZHZaOuKoQi3ZOMi4NkYkpe1p4J7A8BpYAD49hfIy/oqG0+hLomiKP2L5L+1ubn5115S+3OAn4EnwBlgMzCjyt6ZAnQCJ4A7wOs88iRJHvw50HoujuPBoCKwHWiosy8MdfZnAdcHk8dxXFJ3VQbQlCTJvRBCGdRbD4M6uc5glpY3eAihpN5S5w12diSEcCCEcKUO4ljdr15T76ur1FDDLIQQ3qv71EdDOe3Kxj3leRXyk+pxdWnFWod6Wt2bY3de3aSuUHcPBVimHs7mK9WrmeOF6lR1o9qnzskh2ar2qm1qizpfXaPeVGdlmGN5pb09qMxz1Xb1kLqgzn1RyH7JUXW52lr5e/Kqi9qpto7V1atuUzfnARrV7jEib1T76gG2qxdGmXyiekkt1GswPTtek0aBfJp6YySGBfWg2tPQ0FAYgf1stUfdmdcjarbYJEniKIq6gY/Aw+zWHAC+p2labGpqiorFYgGYCEzN7oQdQClN07O1/EfDyGgC0ALMBdYAi4FyK+4H3gLPsxfR1zRNi+NP7nH5J+QntnXe5B5mpfQAAAAASUVORK5CYII=">

<!-- CSS -->
<link rel="stylesheet" type="text/css" href="nimdoc.out.css?v=2.2.4">

<!-- JS -->
<script type="text/javascript" src="dochack.js?v=2.2.4"></script>
</head>
<body>
  <div class="document" id="documentId">
    <div class="container">
      <h1 class="title">backends_guide</h1>
      
<h1 id="compute-backends">Compute Backends</h1><p>ReliQ supports three compute backends, each implementing the same <tt class="docutils literal"><span class="pre">each</span></tt> macro interface.  User code is backend-agnostic — the same <tt class="docutils literal"><span class="pre">for n in each</span></tt> loop works across all three backends.</p>

<h2 id="backend-comparison">Backend Comparison</h2><table border="1" class="docutils"><tr><th>Feature</th><th>OpenCL</th><th>SYCL</th><th>OpenMP</th></tr>
<tr><td>Compilation</td><td>JIT (runtime)</td><td>Pre-compiled (C++)</td><td>Source-level (Nim→C)</td></tr>
<tr><td>Target</td><td>GPUs, FPGAs, CPUs</td><td>Intel/AMD GPUs, CPUs</td><td>CPUs only</td></tr>
<tr><td>Requirements</td><td>OpenCL runtime</td><td>Intel oneAPI (icpx)</td><td>GCC/Clang with OpenMP</td></tr>
<tr><td>Compile flag</td><td><em>(default)</em></td><td><tt class="docutils literal"><span class="pre">BACKEND=sycl</span></tt></td><td><tt class="docutils literal"><span class="pre">BACKEND=openmp</span></tt></td></tr>
<tr><td>SIMD</td><td>GPU warps</td><td>GPU subgroups</td><td>Explicit intrinsics</td></tr>
<tr><td>Memory</td><td>OpenCL buffers</td><td>SYCL USM/buffers</td><td>Shared memory (AoSoA)</td></tr>
<tr><td>Test count</td><td>245 tests</td><td>245 tests</td><td>295 tests</td></tr>
</table>
<h2 id="opencl-backend-default">OpenCL Backend (Default)</h2><p>The OpenCL backend generates kernel source code at compile time and JIT compiles it at runtime.  This is the default backend.</p>

<h3 id="how-it-works">How It Works</h3><p>The <tt class="docutils literal"><span class="pre">each</span></tt> macro in <tt class="docutils literal"><span class="pre">opencl/cldisp</span></tt> receives the loop body as an AST and:</p>
<ol class="simple"><li><strong>Classifies</strong> each assignment expression into a dispatch kind (copy, add, matmul, scalar-mul, etc.)</li>
<li><strong>Gathers</strong> all <tt class="docutils literal"><span class="pre">TensorFieldView</span></tt> symbols referenced in the loop</li>
<li><strong>Detects</strong> stencil neighbor accesses</li>
<li><strong>Generates</strong> an OpenCL C kernel source string with:<ul class="simple"><li>Buffer parameters for each view</li>
<li>Element type declarations (<tt class="docutils literal"><span class="pre">float</span></tt>/<tt class="docutils literal"><span class="pre">double</span></tt>/<tt class="docutils literal"><span class="pre">int</span></tt>/<tt class="docutils literal"><span class="pre">long</span></tt>)</li>
<li>Site indexing with <tt class="docutils literal"><span class="pre">get_global_id(0)</span></tt></li>
<li>Inlined arithmetic matching the expression pattern</li>
</ul>
</li>
<li><strong>JIT-compiles</strong> the kernel using <tt class="docutils literal"><span class="pre">clCreateProgramWithSource</span></tt> and <tt class="docutils literal"><span class="pre">clBuildProgram</span></tt></li>
<li><strong>Dispatches</strong> with <tt class="docutils literal"><span class="pre">clEnqueueNDRangeKernel</span></tt></li>
</ol>

<h3 id="expression-kinds">Expression Kinds</h3><table border="1" class="docutils"><tr><th>Kind</th><th>Example</th><th>Kernel pattern</th></tr>
<tr><td>Copy</td><td><tt class="docutils literal"><span class="pre">vC[n] = vA[n]</span></tt></td><td><tt class="docutils literal"><span class="pre">C[i] = A[i]</span></tt></td></tr>
<tr><td>Add</td><td><tt class="docutils literal"><span class="pre">vC[n] = vA[n] + vB[n]</span></tt></td><td>Element-wise sum</td></tr>
<tr><td>Sub</td><td><tt class="docutils literal"><span class="pre">vC[n] = vA[n] - vB[n]</span></tt></td><td>Element-wise diff</td></tr>
<tr><td>MatMul</td><td><tt class="docutils literal"><span class="pre">vC[n] = vA[n] * vB[n]</span></tt></td><td><tt class="docutils literal"><span class="pre">C[i,j] = Σ A[i,k]*B[k,j]</span></tt></td></tr>
<tr><td>MatVec</td><td><tt class="docutils literal"><span class="pre">vC[n] = vA[n] * vB[n]</span></tt></td><td><tt class="docutils literal"><span class="pre">C[i] = Σ A[i,k]*B[k]</span></tt></td></tr>
<tr><td>ScalarMul</td><td><tt class="docutils literal"><span class="pre">vC[n] = 3.0 * vA[n]</span></tt></td><td><tt class="docutils literal"><span class="pre">C[i] = s * A[i]</span></tt></td></tr>
<tr><td>ScalarAdd</td><td><tt class="docutils literal"><span class="pre">vC[n] = vA[n] + 1.0</span></tt></td><td><tt class="docutils literal"><span class="pre">C[i] = A[i] + s</span></tt></td></tr>
<tr><td>StencilCopy</td><td><tt class="docutils literal"><span class="pre">vC[n] = vA[fwd]</span></tt></td><td>Offset index lookup</td></tr>
</table>
<h3 id="debug-kernels">Debug Kernels</h3><p>Compile with <tt class="docutils literal"><span class="pre">-d:DebugKernels</span></tt> to print generated OpenCL kernel source to stdout at compile time.</p>

<h3 id="modules">Modules</h3><table border="1" class="docutils"><tr><th>Module</th><th>Description</th></tr>
<tr><td><a class="reference external" href="opencl/cldisp.html">opencl/cldisp</a></td><td><tt class="docutils literal"><span class="pre">each</span></tt> macro → OpenCL kernel generation</td></tr>
<tr><td><a class="reference external" href="opencl/clbase.html">opencl/clbase</a></td><td>Platform, device, context, buffer management</td></tr>
</table>
<h3 id="opencl-base-layer">OpenCL Base Layer</h3><p><tt class="docutils literal"><span class="pre">opencl/clbase</span></tt> provides the OpenCL platform and device management:</p>
<p><pre class="listing"><span class="Comment"># Initialization (called automatically by TensorFieldView constructors)</span>
<span class="Identifier">initCL</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
<span class="Identifier">finalizeCL</span><span class="Punctuation">(</span><span class="Punctuation">)</span>

<span class="Comment"># Manual platform selection</span>
<span class="Keyword">let</span> <span class="Identifier">platform</span> <span class="Operator">=</span> <span class="Identifier">firstPlatform</span><span class="Punctuation">(</span><span class="Punctuation">)</span>
<span class="Keyword">let</span> <span class="Identifier">devices</span> <span class="Operator">=</span> <span class="Identifier">getDevices</span><span class="Punctuation">(</span><span class="Identifier">platform</span><span class="Punctuation">)</span>
<span class="Identifier">echo</span> <span class="Identifier">platform</span><span class="Operator">.</span><span class="Identifier">name</span>  <span class="Comment"># e.g., &quot;NVIDIA CUDA&quot;</span>

<span class="Comment"># Device properties</span>
<span class="Identifier">echo</span> <span class="Identifier">devices</span><span class="Punctuation">[</span><span class="DecNumber">0</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">globalMemory</span>
<span class="Identifier">echo</span> <span class="Identifier">devices</span><span class="Punctuation">[</span><span class="DecNumber">0</span><span class="Punctuation">]</span><span class="Operator">.</span><span class="Identifier">maxWorkItems</span></pre></p>

<h2 id="sycl-backend">SYCL Backend</h2><p>The SYCL backend dispatches to pre-compiled C++ kernel templates in a shared library (<tt class="docutils literal"><span class="pre">libreliq_sycl.so</span></tt>), avoiding JIT compilation overhead.</p>

<h3 id="how-it-works">How It Works</h3><p>The <tt class="docutils literal"><span class="pre">each</span></tt> macro in <tt class="docutils literal"><span class="pre">sycl/sycldisp</span></tt>:</p>
<ol class="simple"><li><strong>Analyzes</strong> the AST (same expression classification as OpenCL)</li>
<li><strong>Builds an execution plan</strong> for complex expressions involving temporaries</li>
<li><strong>Dispatches</strong> to typed C++ template functions via FFI:<ul class="simple"><li><tt class="docutils literal"><span class="pre">sycl_kernel_copy_f64(queue, bufA, bufC, nSites, elems)</span></tt></li>
<li><tt class="docutils literal"><span class="pre">sycl_kernel_matmul_f64(queue, bufA, bufB, bufC, nSites, rows, cols)</span></tt></li>
<li>etc.</li>
</ul>
</li>
<li>Each kernel function is a <tt class="docutils literal"><span class="pre">sycl::handler::parallel_for</span></tt> with type-specialized inner loops</li>
</ol>

<h3 id="building-the-sycl-wrapper">Building the SYCL Wrapper</h3><p><pre class="listing"># Build libreliq_sycl.so (requires Intel oneAPI or hipSYCL)
make sycl-lib

# Then build/test with SYCL backend
make tensorview BACKEND=sycl
make test-sycl</pre></p>

<h3 id="typeminusspecialized-kernels">Type-Specialized Kernels</h3><p>The SYCL wrapper provides kernels for each element type:</p>
<ul class="simple"><li><tt class="docutils literal"><span class="pre">float32</span></tt> (<tt class="docutils literal"><span class="pre">sycl_kernel_*_f32</span></tt>)</li>
<li><tt class="docutils literal"><span class="pre">float64</span></tt> (<tt class="docutils literal"><span class="pre">sycl_kernel_*_f64</span></tt>)</li>
<li><tt class="docutils literal"><span class="pre">int32</span></tt> (<tt class="docutils literal"><span class="pre">sycl_kernel_*_i32</span></tt>)</li>
<li><tt class="docutils literal"><span class="pre">int64</span></tt> (<tt class="docutils literal"><span class="pre">sycl_kernel_*_i64</span></tt>)</li>
</ul>
<p>Plus complex-number variants for <tt class="docutils literal"><span class="pre">Complex64</span></tt> fields.</p>

<h3 id="stencil-kernels">Stencil Kernels</h3><p>Pre-compiled stencil kernels accept an offset buffer and perform neighbor lookups on-device:</p>
<table border="1" class="docutils"><tr><th>Kernel</th><th>Description</th></tr>
<tr><td><tt class="docutils literal"><span class="pre">kernelStencilCopy</span></tt></td><td>Copy from neighbor site</td></tr>
<tr><td><tt class="docutils literal"><span class="pre">kernelStencilScalarMul</span></tt></td><td>Scalar × neighbor value</td></tr>
<tr><td><tt class="docutils literal"><span class="pre">kernelStencilAdd</span></tt></td><td>Sum of site and neighbor</td></tr>
</table>
<h3 id="modules">Modules</h3><table border="1" class="docutils"><tr><th>Module</th><th>Description</th></tr>
<tr><td><a class="reference external" href="sycl/sycldisp.html">sycl/sycldisp</a></td><td><tt class="docutils literal"><span class="pre">each</span></tt> macro → native SYCL dispatch</td></tr>
<tr><td><a class="reference external" href="sycl/syclbase.html">sycl/syclbase</a></td><td>Queue/buffer management</td></tr>
<tr><td><a class="reference external" href="sycl/syclwrap.html">sycl/syclwrap</a></td><td>Low-level C++ FFI (60+ kernel functions)</td></tr>
</table>
<h2 id="openmp-backend">OpenMP Backend</h2><p>The OpenMP backend generates SIMD-vectorized C code with explicit intrinsic calls, targeting CPU architectures.</p>

<h3 id="how-it-works">How It Works</h3><p>The <tt class="docutils literal"><span class="pre">each</span></tt> macro in <tt class="docutils literal"><span class="pre">openmp/ompdisp</span></tt>:</p>
<ol class="simple"><li><strong>Analyzes</strong> the AST (same expression classification)</li>
<li><strong>Determines</strong> if SIMD vectorization is applicable</li>
<li><strong>Generates</strong> C code with:<ul class="simple"><li><tt class="docutils literal"><span class="pre">#pragma omp parallel for</span></tt> for outer loop parallelism</li>
<li>SIMD intrinsics (AVX2/AVX-512) for inner loop vectorization</li>
<li>AoSoA memory access pattern matching the <tt class="docutils literal"><span class="pre">SimdLatticeLayout</span></tt></li>
</ul>
</li>
</ol>

<h3 id="simdminusvectorized-views">SIMD-Vectorized Views</h3><p>When using the OpenMP backend, <tt class="docutils literal"><span class="pre">TensorFieldView</span></tt> can use a SIMD-aware AoSoA layout:</p>
<p><pre class="listing"><span class="Comment"># Default SIMD grid (auto-distributed based on VectorWidth)</span>
<span class="Keyword">var</span> <span class="Identifier">vA</span> <span class="Operator">=</span> <span class="Identifier">localA</span><span class="Operator">.</span><span class="Identifier">newTensorFieldView</span><span class="Punctuation">(</span><span class="Identifier">iokRead</span><span class="Punctuation">)</span>

<span class="Comment"># Explicit SIMD grid</span>
<span class="Keyword">var</span> <span class="Identifier">vB</span> <span class="Operator">=</span> <span class="Identifier">localB</span><span class="Operator">.</span><span class="Identifier">newTensorFieldView</span><span class="Punctuation">(</span><span class="Identifier">iokRead</span><span class="Punctuation">,</span> <span class="Punctuation">[</span><span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">1</span><span class="Punctuation">,</span> <span class="DecNumber">8</span><span class="Punctuation">]</span><span class="Punctuation">)</span></pre></p>
<p>The SIMD grid controls how lattice sites are grouped into SIMD lanes. With <tt class="docutils literal"><span class="pre">VectorWidth=8</span></tt> (AVX-512), 8 consecutive sites along the innermost SIMD dimension are processed simultaneously.</p>

<h3 id="loop-patterns">Loop Patterns</h3><p>The SIMD backend uses an outer/inner loop pattern:</p>
<p><pre class="listing"><span class="Comment"># Outer loop: iterates over SIMD groups (OpenMP parallel)</span>
<span class="Comment"># Inner loop: iterates over SIMD lanes (vectorized)</span>
<span class="Keyword">for</span> <span class="Identifier">outer</span> <span class="Keyword">in</span> <span class="FloatNumber">0.</span><span class="Operator">.&lt;</span><span class="Identifier">nSitesOuter</span><span class="Punctuation">:</span>
  <span class="Keyword">for</span> <span class="Identifier">lane</span> <span class="Keyword">in</span> <span class="FloatNumber">0.</span><span class="Operator">.&lt;</span><span class="Identifier">VectorWidth</span><span class="Punctuation">:</span>
    <span class="Comment"># Each lane processes one site within the SIMD group</span></pre></p>
<p>The <tt class="docutils literal"><span class="pre">eachOuter</span></tt> macro in <tt class="docutils literal"><span class="pre">openmp/ompsimd</span></tt> provides direct access to this pattern for low-level SIMD programming.</p>

<h3 id="simd-intrinsics">SIMD Intrinsics</h3><p>The OpenMP backend can use hardware-specific SIMD intrinsics:</p>
<p><pre class="listing"><span class="Comment"># SIMD vector operations (compile with -d:AVX2 or -d:AVX512)</span>
<span class="Keyword">import</span> <span class="Identifier">reliq</span>

<span class="Keyword">var</span> <span class="Identifier">a</span> <span class="Operator">=</span> <span class="Identifier">SimdF64x4</span><span class="Punctuation">(</span><span class="Identifier">data</span><span class="Punctuation">:</span> <span class="Punctuation">[</span><span class="FloatNumber">1.0</span><span class="Punctuation">,</span> <span class="FloatNumber">2.0</span><span class="Punctuation">,</span> <span class="FloatNumber">3.0</span><span class="Punctuation">,</span> <span class="FloatNumber">4.0</span><span class="Punctuation">]</span><span class="Punctuation">)</span>
<span class="Keyword">var</span> <span class="Identifier">b</span> <span class="Operator">=</span> <span class="Identifier">SimdF64x4</span><span class="Punctuation">(</span><span class="Identifier">data</span><span class="Punctuation">:</span> <span class="Punctuation">[</span><span class="FloatNumber">5.0</span><span class="Punctuation">,</span> <span class="FloatNumber">6.0</span><span class="Punctuation">,</span> <span class="FloatNumber">7.0</span><span class="Punctuation">,</span> <span class="FloatNumber">8.0</span><span class="Punctuation">]</span><span class="Punctuation">)</span>
<span class="Keyword">var</span> <span class="Identifier">c</span> <span class="Operator">=</span> <span class="Identifier">a</span> <span class="Operator">+</span> <span class="Identifier">b</span>              <span class="Comment"># [6.0, 8.0, 10.0, 12.0]</span>
<span class="Keyword">let</span> <span class="Identifier">s</span> <span class="Operator">=</span> <span class="Identifier">a</span><span class="Operator">.</span><span class="Identifier">sum</span><span class="Punctuation">(</span><span class="Punctuation">)</span>            <span class="Comment"># 10.0</span></pre></p>

<h3 id="modules">Modules</h3><table border="1" class="docutils"><tr><th>Module</th><th>Description</th></tr>
<tr><td><a class="reference external" href="openmp/ompdisp.html">openmp/ompdisp</a></td><td><tt class="docutils literal"><span class="pre">each</span></tt> macro → SIMD-vectorized code</td></tr>
<tr><td><a class="reference external" href="openmp/ompbase.html">openmp/ompbase</a></td><td>OpenMP initialization, thread management</td></tr>
<tr><td><a class="reference external" href="openmp/ompsimd.html">openmp/ompsimd</a></td><td>SIMD-aware dispatch, <tt class="docutils literal"><span class="pre">eachOuter</span></tt> macro</td></tr>
</table>
<h2 id="building-and-testing">Building and Testing</h2><p><pre class="listing"># Build with specific backend
make tensorview                    # OpenCL (default)
make tensorview BACKEND=openmp     # OpenMP
make tensorview BACKEND=sycl       # SYCL

# Run all backend tests
make test          # All backends (1,660 tests)
make test-core     # Core tests (875)
make test-opencl   # OpenCL tests (245)
make test-openmp   # OpenMP tests (295)
make test-sycl     # SYCL tests (245)</pre> </p>



      <div class="twelve-columns footer">
        <span class="nim-sprite"></span>
        <br>
        <small style="color: var(--hint);">Made with Nim. Generated: 2026-02-07 06:49:56 UTC</small>
      </div>
    </div>
  </div>
  
</body>
</html>
